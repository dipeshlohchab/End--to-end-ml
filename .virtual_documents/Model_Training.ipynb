








import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import statistics as st
import warnings
warnings.filterwarnings("ignore")
sns.set(rc={"figure.figsize": (15, 6)})
pd.pandas.set_option("display.max_columns", None)


df= pd.read_csv('adult.csv')


df.head()


df.shape


df.rename(columns={'education.num': 'education_number',
                   'marital.status':'marital_status',
                   'capital.gain':'capital_gain',
                   'capital.loss':'capital_loss',
                   'hours.per.week':'hours_per_week',
                   'native.country':'native_country'
                  }, inplace=True)



df.head()


df.columns


df.dtypes


df.info()


df.isnull().sum()


df.duplicated().sum()


df.drop_duplicates(inplace=True)


df.duplicated().sum()


df.describe()


cat_col= df.select_dtypes(include='object').columns
num_col= df.select_dtypes(exclude='object').columns


cat_col


num_col


df.workclass.value_counts()


for i in cat_col:
    print(i)
    print(df[i].unique())
    print()
    print('*******************************************************************************')
    print()


# remove ? and replace with mode value # .mode()
df["workclass"] = df["workclass"].replace("?",df["workclass"].mode()[0])
df["occupation"] = df["occupation"].replace("?",df["occupation"].mode()[0])
df["native_country"] = df["native_country"].replace("?",df["native_country"].mode()[0])





sns.set(rc={"figure.figsize": (15, 6)})
colmns1 = ['workclass', 'education', 'marital_status', 'occupation']

for i in range(0,len(colmns1)):
    plt.style.use('fivethirtyeight')
    plt.subplot(2,4,i+1)
    sns.countplot(x=df[colmns1[i]])
    plt.xticks(size=15,rotation=90)
    plt.tight_layout()


plt.style.available


colmns2 = ['relationship', 'race', 'sex', 'income']

for i in range(0,len(colmns2)):
    plt.subplot(2,4,i+1)
    sns.countplot(x=df[colmns2[i]])
    plt.xticks(size=15,rotation=90)



plt.suptitle("Distribution Graphs of numerical features")
for i in range(0,len(num_col)):
    plt.subplot(2,4,i+1)
    sns.distplot(x=df[num_col[i]])
    plt.xticks(size=15,rotation=90)



plt.suptitle("Boxplot of numerical features to see outlayers ")
for i in range(0,len(num_col)):
    plt.subplot(2,4,i+1)
    sns.boxplot(x=df[num_col[i]])
    plt.xticks(size=15,rotation=90)
    plt.tight_layout()


df.head()


salary = pd.crosstab(df['income'],df['workclass'])
salary.plot(kind='bar')


education = pd.crosstab(df['income'],df['education'])
education.plot(kind="bar")


marital_status = pd.crosstab(df['income'],df['marital_status'])
marital_status.plot(kind="bar")


occupation = pd.crosstab(df['income'],df['occupation'])
occupation.plot(kind="bar")


relationship = pd.crosstab(df['income'],df['relationship'])
relationship.plot(kind="bar")


sex = pd.crosstab(df['income'],df['sex'])
sex.plot(kind="bar")


from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
cat_col = list(cat_col)
cat_col.remove('income')

for i in cat_col:
    le.fit(df[i])
    df[i] = le.transform(df[i])



df.head()


df['income']=df.income.map({'<=50K': 0, '>50K': 1})


df.head()


sns.heatmap(df.corr(), annot=True)


df.drop(columns=['fnlwgt'], inplace=True)


df.to_csv('cleaned_data.csv', index=False)


df.shape





x=df.drop(columns=['income'])
y=df.income


cat_col = x.select_dtypes(include="object").columns
num_col = x.select_dtypes(exclude="object").columns
print(cat_col)
print(num_col)


from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer


num_pipline = Pipeline(
    steps=[
        ("imputer",SimpleImputer(strategy="median")),
        ("scaler",StandardScaler())
    ]

)

cato_pipline = Pipeline(
    steps=[
        ("imputer",SimpleImputer(strategy="most_frequent")),
        ("scaler",StandardScaler())
    ]

)

preprocessor = ColumnTransformer([
    ("num_pipline",num_pipline,num_col)
])


from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=42)


from imblearn.over_sampling import SMOTE

smote = SMOTE(sampling_strategy='auto', random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

X_test_smote, y_test_smote = smote.fit_resample(X_test, y_test)



X_train_smote.shape


X_test_smote.shape


from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score,f1_score,classification_report,ConfusionMatrixDisplay


def performance_metrics(test, predict):
    confusionmetrix = confusion_matrix(test, predict)
    precision = precision_score(test, predict)
    recall = recall_score(test, predict)
    f1score = f1_score(test, predict)
    accuracyscore = accuracy_score(test, predict)

    print(f"CONFUSION_MATRIX:\n{confusionmetrix}")
    print(f"PRECISION_SCORE: {precision}")
    print(f"RECALL_SCORE: {recall}")
    print(f"F1_SCORE: {f1score}")
    print(f"ACCURACY_SCORE: {accuracyscore}")

    return confusionmetrix, precision, recall, f1score, accuracyscore



lr = LogisticRegression()
pram = {
    "class_weight":["balanced"],
    'penalty': ['l1', 'l2'],
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'solver': ['liblinear', 'saga']

}
grid = GridSearchCV(estimator=lr,param_grid=pram,cv=5,n_jobs=-1, verbose=3)
grid.fit(X_train_smote,y_train_smote)


lr=LogisticRegression(C=0.1, class_weight='balanced', penalty='l1', solver='liblinear')
lr.fit(X_train_smote,y_train_smote)


lr_pred= lr.predict(X_test_smote)


metrics = performance_metrics(y_test_smote, lr_pred)


sns.heatmap(confusion_matrix(y_test_smote, lr_pred), annot=True, fmt="d")
plt.xlabel('Predicted Labels')
plt.ylabel('Actual Labels')
plt.title('Confusion Matrix with Labels')
plt.show()


print(classification_report(y_test_smote,lr_pred))





dr = DecisionTreeClassifier()
param_grid = {
    "class_weight":["balanced"],
    "criterion":['gini',"entropy","log_loss"],
    "splitter":['best','random'],
    "max_depth":[3,4,5,6],
    "min_samples_split":[2,3,4,5],
    "min_samples_leaf":[1,2,3],
    "max_features":["auto","sqrt","log2"]
}
grid_search = GridSearchCV(estimator=dr,param_grid=param_grid,cv=5,scoring="accuracy")
grid_search.fit(X_train_smote,y_train_smote)


dt=DecisionTreeClassifier(class_weight='balanced', criterion='entropy', max_depth=6, max_features='sqrt', min_samples_split=4)
dt.fit(X_train_smote,y_train_smote)


dt_pred=dt.predict(X_test_smote)


metrics = performance_metrics(y_test_smote, dt_pred)


sns.heatmap(confusion_matrix(y_test_smote, dt_pred), annot=True, fmt="d")
plt.xlabel('Predicted Labels')
plt.ylabel('Actual Labels')
plt.title('Confusion Matrix with Labels')
plt.show()


print(classification_report(y_test_smote,dt_pred))





rf = RandomForestClassifier()
param_grid = {
    "class_weight":["balanced"],
    'n_estimators': [20, 50, 30],
    'max_depth': [10, 8, 5],
    'min_samples_split': [2, 5, 10],
}
grid_search = GridSearchCV(estimator=rf,param_grid=param_grid,cv=5,scoring="accuracy")
grid_search.fit(X_train_smote,y_train_smote)


grid_search.best_estimator_


rf= RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=50, min_samples_split=5)


rf.fit(X_train_smote,y_train_smote)


rf_pred= rf.predict(X_test_smote)


metrics = performance_metrics(y_test_smote, rf_pred)


sns.heatmap(confusion_matrix(y_test_smote, rf_pred), annot=True, fmt="d")
plt.xlabel('Predicted Labels')
plt.ylabel('Actual Labels')
plt.title('Confusion Matrix with Labels')
plt.show()


print(classification_report(y_test_smote,rf_pred))


df.columns


import pickle 

with open('model.pkl', 'rb') as file:
    model= pickle.load(file)





